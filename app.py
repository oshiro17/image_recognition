# app.py
# -*- coding: utf-8 -*-
"""
ğŸ“· åŸºæº–æ’®å½± â†’ è¨­å®š â†’ ç›£è¦– ã®3ã‚¹ãƒ†ãƒƒãƒ—UI
- èµ·å‹•ç›´å¾Œã¯ã€ŒåŸºæº–ã‚’æ’®å½±/èª­ã¿è¾¼ã¿ã€ã®ã¿è¡¨ç¤º
- åŸºæº–ç¢ºå®šå¾Œã«è¨­å®šï¼ˆæ’®å½±é–“éš”ãƒ»æ•´åˆ—ãªã©ï¼‰
- ã‚¹ã‚¿ãƒ¼ãƒˆã§ãƒ«ãƒ¼ãƒ—ï¼ˆåŸºæº– vs ç¾åœ¨ï¼‰å·®åˆ†ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
- ã™ã¹ã¦ã®æ’®å½±ï¼†å·®åˆ†ã¯ runs/<session>/ ã«ä¿å­˜ã€å±¥æ­´ã‚®ãƒ£ãƒ©ãƒªãƒ¼ã§è¦‹è¿”ã—ï¼†ZIP DL
"""

import os
import io
import glob
import time
import json
import shutil
import cv2
import numpy as np
import streamlit as st
import sys
from datetime import datetime
from pathlib import Path
from typing import Tuple, Dict, Any, Optional

# --- Optional: click-to-pick (fallback to sliders if unavailable)
try:
    from st_click_detector import click_detector as _click_detector  # pip install st-click-detector
    _HAS_CLICK = True
except Exception:
    _HAS_CLICK = False

# è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆå­˜åœ¨ã™ã‚Œã°pkgã€ãªã‘ã‚Œã°JSãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    from streamlit_autorefresh import st_autorefresh
    _AUTOREFRESH_IMPL = "pkg"
except Exception:
    from streamlit.components.v1 import html as _html
    def st_autorefresh(interval: int = 5_000, key: str = "tick", limit: int | None = None):
        _html(f"<script>setTimeout(()=>window.location.reload(), {interval});</script>", height=0)
        return None
    _AUTOREFRESH_IMPL = "js"

# ---- æ—¢å­˜ core ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ----
from core.io_utils import ensure_same_size
from core.align import camera_misaligned, align_ecc, align_homography
# from core.diff import difference_boxes, fused_diff_mask, boxes_from_mask, quality_harmonize_pair
from core.vis import make_boxes_overlay_transparent, draw_clusters_only
from core.cluster import cluster_dense_boxes

from core.diff import difference_boxes, fused_diff_mask, boxes_from_mask

from core.quality import quality_harmonize_pair

# ============ è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›£è¦–ï¼ˆLabãƒ™ãƒ¼ã‚¹ï¼‰ ãƒ˜ãƒ«ãƒ‘ ============

def _lab(img: np.ndarray) -> np.ndarray:
    return cv2.cvtColor(img, cv2.COLOR_BGR2LAB).astype(np.float32)



def draw_target_preview(img: np.ndarray, x: int, y: int, r: int) -> np.ndarray:
    """Draw a circle and small crosshair at (x,y)."""
    vis = img.copy()
    x = int(x); y = int(y); r = int(r)
    cv2.circle(vis, (x, y), r, (0, 255, 255), 2)
    cv2.drawMarker(vis, (x, y), (0, 255, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)
    return vis


# --- Optional clickable image helper
def clickable_pick_xy(img_rgb: np.ndarray, key: str = "clickpick") -> tuple[int | None, int | None]:
    """
    Show an image; if st-click-detector is available, return clicked (x,y) in image coordinates.
    Otherwise, return (None, None) and the caller should fallback to sliders.
    """
    if not _HAS_CLICK:
        st.image(img_rgb, use_container_width=True)
        return None, None
    h, w = img_rgb.shape[:2]
    # Render clickable image
    events = _click_detector(img_rgb, key=key)  # returns dict with keys like 'x', 'y' in CSS pixels
    # st-click-detector returns proportional coordinates as 'x','y' in the shown image space (0..displayW/H).
    if events and "x" in events and "y" in events and events["x"] is not None and events["y"] is not None:
        # Map from displayed size back to original by keeping ratios
        disp_w = events.get("display_width", w) or w
        disp_h = events.get("display_height", h) or h
        rx = float(events["x"]) / float(max(1, disp_w))
        ry = float(events["y"]) / float(max(1, disp_h))
        x = int(np.clip(round(rx * w), 0, w - 1))
        y = int(np.clip(round(ry * h), 0, h - 1))
        return x, y
    return None, None


def sample_lab_stats(img: np.ndarray, x: int, y: int, r: int, use_l: bool = False) -> dict:
    """åŸºæº–ç”»åƒã‹ã‚‰ (x,y) å‘¨è¾ºåŠå¾„ r ã® Lab çµ±è¨ˆé‡ï¼ˆå¹³å‡/åˆ†æ•£ï¼‰ã‚’å–å¾—ã€‚
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ a,b ã®ã¿ã‚’ä½¿ã„ã€use_l=True ãªã‚‰ L ã‚‚ä½µç”¨ã§ãã‚‹ã€‚
    æˆ»ã‚Šå€¤: {mean: (L,a,b), std: (L,a,b)}
    """
    h, w = img.shape[:2]
    x = int(np.clip(x, 0, w - 1)); y = int(np.clip(y, 0, h - 1)); r = int(max(1, r))
    lab = _lab(img)
    yy, xx = np.ogrid[:h, :w]
    mask = (xx - x) ** 2 + (yy - y) ** 2 <= r ** 2
    if mask.sum() < 5:
        # æœ€ä½é™ã®ç”»ç´ æ•°ãŒç„¡ã‘ã‚Œã°å‘¨å›²ã«æ‹¡å¼µ
        r = max(3, r + 2)
        mask = (xx - x) ** 2 + (yy - y) ** 2 <= r ** 2
    vals = lab[mask]
    mean = vals.mean(axis=0)
    std = vals.std(axis=0) + 1e-6
    return {
        "mean": (float(mean[0]), float(mean[1]), float(mean[2])),
        "std": (float(std[0]), float(std[1]), float(std[2])),
        "use_l": bool(use_l)
    }


def _target_mask_for_img(img: np.ndarray, target: dict, roi: Optional[tuple] = None) -> np.ndarray:
    """ç¾åœ¨ç”»åƒã«å¯¾ã—ã¦ã€target(Lab ã‚¬ã‚¦ã‚¹è¿‘å‚)ã«å±ã™ã‚‹ç”»ç´ ãƒã‚¹ã‚¯ã‚’è¿”ã™ï¼ˆuint8ï¼‰ã€‚
    roi=(x,y,w,h) ãŒã‚ã‚Œã°ãã®ç¯„å›²å†…ã§è©•ä¾¡ã€‚
    æ—¢å®šã§ã¯ a,b ã®ã¿ã®æ¥•å††è·é›¢ã€target["use_l"] ãŒçœŸãªã‚‰ L ã‚‚å«ã‚ã‚‹ã€‚
    target ä¾‹:
      {"name": str, "mean": (L,a,b), "std": (L,a,b), "k_sigma": 2.5, "use_l": False, "roi": (x,y,w,h)}
    """
    lab = _lab(img)
    h, w = lab.shape[:2]
    if roi is not None:
        x, y, rw, rh = [int(v) for v in roi]
        x = max(0, x); y = max(0, y); rw = max(1, rw); rh = max(1, rh)
        x2 = min(w, x + rw); y2 = min(h, y + rh)
        sub = lab[y:y2, x:x2]
        off = (x, y)
    else:
        sub = lab
        off = (0, 0)

    meanL, meana, meanb = target.get("mean", (0, 0, 0))
    stdL, stda, stdb = target.get("std", (1, 1, 1))
    k = float(target.get("k_sigma", 2.5))
    use_l = bool(target.get("use_l", False))

    L = sub[..., 0]; A = sub[..., 1]; B = sub[..., 2]
    da = (A - meana) / (stda + 1e-6)
    db = (B - meanb) / (stdb + 1e-6)
    dist2 = da * da + db * db
    if use_l:
        dL = (L - meanL) / (stdL + 1e-6)
        dist2 = dist2 + dL * dL
    mask = (dist2 <= (k * k)).astype(np.uint8) * 255
    out = np.zeros((h, w), np.uint8)
    out[off[1]:off[1] + mask.shape[0], off[0]:off[0] + mask.shape[1]] = mask
    return out


def ratio_for_target(img: np.ndarray, target: dict) -> float:
    """ç”»åƒ img ã«ãŠã‘ã‚‹ target ç”»ç´ ã®å‰²åˆï¼ˆ0..1ï¼‰ã‚’è¿”ã™ã€‚"""
    roi = target.get("roi")
    m = _target_mask_for_img(img, target, roi)
    if roi is not None:
        x, y, w, h = [int(v) for v in roi]
        denom = max(1, w * h)
        return float((m[y:y+h, x:x+w] > 0).sum()) / float(denom)
    else:
        return float((m > 0).sum()) / float(m.size)


# --- è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¿½åŠ /ç¢ºèªUIï¼ˆåŸºæº–ãŒå­˜åœ¨ã™ã‚‹å‰æï¼‰
def render_color_target_editor():
    """è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¿½åŠ /ç¢ºèªUIï¼ˆåŸºæº–ãŒå­˜åœ¨ã™ã‚‹å‰æï¼‰ã€‚ss.targets ã‚’ç›´æ¥æ›´æ–°ã™ã‚‹ã€‚"""
    if not ss.get("baseline_path"):
        st.info("åŸºæº–ç”»åƒãŒæœªè¨­å®šã§ã™ã€‚")
        return
    base = cv2.imread(ss.baseline_path, cv2.IMREAD_COLOR)
    if base is None:
        st.warning("åŸºæº–ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    h, w = base.shape[:2]
    cols = st.columns([2,1])
    with cols[0]:
        st.caption("åŸºæº–ç”»åƒä¸Šã§è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æŒ‡å®šã—ã¾ã™ã€‚ã‚¯ãƒªãƒƒã‚¯å¯¾å¿œï¼ˆst-click-detectorï¼‰ãŒç„¡ã„å ´åˆã¯ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        img_rgb = bgr2rgb(base)
        cx, cy = clickable_pick_xy(img_rgb, key="pick_target_xy_cfg")
        default_x = w//2 if cx is None else cx
        default_y = h//2 if cy is None else cy
        x = st.slider("X", 0, max(1, w-1), int(default_x), key="t_x")
        y = st.slider("Y", 0, max(1, h-1), int(default_y), key="t_y")
        r = st.slider("åŠå¾„ r", 3, max(5, min(h,w)//4), 20, key="t_r")
        preview = draw_target_preview(img_rgb, x, y, r)
        st.image(preview, caption="ä½ç½®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", use_container_width=True)
    with cols[1]:
        name = st.text_input("åå‰", value=f"target_{len(ss.targets)+1}", key="t_name")
        direction = st.selectbox("ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶", ["decrease", "increase"], help="decrease: æ¸›ã£ãŸã‚‰è­¦å‘Š / increase: å¢—ãˆãŸã‚‰è­¦å‘Š", key="t_dir")
        threshold_pct = st.slider("å¤‰åŒ–ã—ãã„å€¤(%)", 1, 50, 10, key="t_thr")
        k_sigma = st.slider("è‰²ã‚†ã‚‹ã• kÏƒ", 1.0, 4.0, 2.5, 0.1, key="t_ks")
        use_l = st.checkbox("æ˜åº¦Lã‚‚ä½¿ã†", value=False, help="è‰²å‘³ãƒ¡ã‚¤ãƒ³ã§ååˆ†ãªã‚‰OFFæ¨å¥¨", key="t_useL")
        roi_enable = st.checkbox("ROIã‚’æŒ‡å®šã™ã‚‹", value=False, key="t_roi_en")
        roi = None
        if roi_enable:
            rx = st.slider("ROI x", 0, w-1, 0, key="t_rx")
            ry = st.slider("ROI y", 0, h-1, 0, key="t_ry")
            rw = st.slider("ROI w", 1, w-rx, w, key="t_rw")
            rh = st.slider("ROI h", 1, h-ry, h, key="t_rh")
            roi = (rx, ry, rw, rh)
        if st.button("ï¼‹ ã“ã®è‰²ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è¿½åŠ ", type="primary", use_container_width=True, key="t_add"):
            stats = sample_lab_stats(base, x, y, r, use_l=use_l)
            tmp_target = {
                "name": name,
                "mean": stats["mean"],
                "std": stats["std"],
                "use_l": use_l,
                "k_sigma": float(k_sigma),
                "direction": direction,
                "threshold_pct": float(threshold_pct),
                "roi": roi,
            }
            base_ratio = ratio_for_target(base, tmp_target)
            tmp_target["base_ratio"] = float(base_ratio)
            ss.targets.append(tmp_target)
            st.success(f"è¿½åŠ ã—ã¾ã—ãŸ: {name} (åŸºæº–å‰²åˆ {base_ratio*100:.2f}%)")
        show_mask_preview = st.checkbox("ã“ã®è¨­å®šã§ãƒã‚¹ã‚¯ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", value=False, key="t_preview")
        if show_mask_preview:
            tmp = {
                "name": name, "k_sigma": float(k_sigma), "use_l": use_l,
                "mean": sample_lab_stats(base, x, y, r, use_l)["mean"],
                "std": sample_lab_stats(base, x, y, r, use_l)["std"],
                "roi": roi
            }
            pm = _target_mask_for_img(base, tmp, roi)
            st.image(pm, clamp=True, caption="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚¹ã‚¯ï¼ˆåŸºæº–ç”»åƒï¼‰", use_container_width=True)
    # è¿½åŠ æ¸ˆã¿ä¸€è¦§
    if ss.targets:
        st.markdown("#### è¿½åŠ æ¸ˆã¿ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ")
        del_idxs = []
        for i, t in enumerate(ss.targets):
            cols2 = st.columns([3,2,2,2,1])
            cols2[0].write(f"**{t['name']}**")
            cols2[1].write(f"æ¡ä»¶: {t['direction']} / ã—ãã„å€¤ {t['threshold_pct']}%")
            cols2[2].write(f"kÏƒ={t.get('k_sigma',2.5)} / Lä½¿ç”¨={t.get('use_l',False)}")
            cols2[3].write(f"åŸºæº–å‰²åˆ: {t.get('base_ratio',0.0)*100:.2f}%")
            if cols2[4].button("ğŸ—‘ï¸", key=f"cfg_del_t_{i}"):
                del_idxs.append(i)
        for i in reversed(del_idxs):
            ss.targets.pop(i)



# ============ å…±é€šUI ============

st.set_page_config(page_title="å·®åˆ†ç›£è¦– ğŸ“¸", layout="wide")
st.markdown(
    """
    <style>
      .big-badge {font-size: 20px; padding: 6px 14px; border-radius: 999px; display:inline-block;}
      .ok-badge  {background:#eafaf1; color:#1f9254; border:1px solid #b8e6cd;}
      .ng-badge  {background:#ffefef; color:#c0392b; border:1px solid #ffd0d0;}
      .pill      {background:#f3f6ff; color:#3b5bcc; border:1px solid #d9e2ff; border-radius:999px; padding:2px 10px; font-size:12px;}
      .card {padding:14px; border-radius:14px; border:1px solid #eee; background: white; box-shadow: 0 2px 10px rgba(0,0,0,0.03);}
    </style>
    """,
    unsafe_allow_html=True
)
st.title("ğŸŒ¸ å·®åˆ†ç›£è¦–")

# ---- ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ï¼ˆç›£è¦– / ãƒ†ã‚¹ãƒˆï¼‰----
ss = st.session_state
ss.setdefault("mode", "ç›£è¦–")
ss.setdefault("test_pairs", [])  # [(pathA, pathB)]
mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰", ["ç›£è¦–", "ãƒ†ã‚¹ãƒˆ"], index=(0 if ss.get("mode","ç›£è¦–")=="ç›£è¦–" else 1))
ss.mode = mode

# ============ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ============

def _init_state():
    ss.setdefault("phase", "INIT")          # INIT -> BASELINE_SET -> CONFIG_SET -> RUNNING/PAUSED
    ss.setdefault("session_dir", "")        # runs/<session_name>
    ss.setdefault("baseline_path", "")      # ä¿å­˜å…ˆ
    ss.setdefault("config", {})             # è¨­å®šä¿å­˜
    ss.setdefault("next_shot_ts", 0.0)      # æ¬¡å›æ’®å½±æ™‚åˆ»
    ss.setdefault("cam_diag", {})           # ã‚«ãƒ¡ãƒ©æƒ…å ±
    ss.setdefault("last_metrics", None)     # ç›´è¿‘ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    ss.setdefault("backend", "AVFOUNDATION" if sys.platform == "darwin" else "AUTO")
    ss.setdefault("cam_index", 0)
    ss.setdefault("targets", [])  # ç›£è¦–ã™ã‚‹è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒªã‚¹ãƒˆ

_init_state()

# ============ ãƒ©ãƒ³ï¼ˆä¿å­˜å…ˆï¼‰ ============

def new_session_dir() -> str:
    root = Path("runs")
    root.mkdir(exist_ok=True)
    name = datetime.now().strftime("%Y-%m-%d_%H%M%S")
    session = root / name
    (session / "captures").mkdir(parents=True, exist_ok=True)
    (session / "diffs").mkdir(parents=True, exist_ok=True)
    return str(session)

def save_config(session_dir: str, cfg: Dict[str, Any]) -> None:
    with open(Path(session_dir)/"config.json", "w", encoding="utf-8") as f:
        json.dump(cfg, f, ensure_ascii=False, indent=2)

def append_index(session_dir: str, row: Dict[str, Any]) -> None:
    import csv
    idx = Path(session_dir)/"index.csv"
    new = not idx.exists()
    with open(idx, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=["ts","capture","aligned","ssim","diff_ratio","boxes"])
        if new: w.writeheader()
        w.writerow(row)

def make_zip(session_dir: str) -> str:
    base = Path(session_dir).resolve()
    out = base.parent / (base.name + ".zip")
    if out.exists():
        out.unlink()
    shutil.make_archive(str(out.with_suffix("")), "zip", root_dir=str(base))
    return str(out)

# ============ ã‚«ãƒ¡ãƒ©ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============

def _backend_flag(name: str) -> Optional[int]:
    m = {
        "AVFOUNDATION": getattr(cv2, "CAP_AVFOUNDATION", None),
        "QT": getattr(cv2, "CAP_QT", None),
        "V4L2": getattr(cv2, "CAP_V4L2", None),
        "DSHOW": getattr(cv2, "CAP_DSHOW", None),
        "AUTO": None,
    }
    return m.get((name or "AUTO").upper())

def capture_frame(index: int, backend: str, warmup: int = 5, size: Tuple[int,int] | None=None) -> Tuple[Optional[np.ndarray], Dict[str,Any]]:
    order = [backend] + [b for b in (("AVFOUNDATION","QT") if sys.platform=="darwin" else ("V4L2","DSHOW")) if b!=backend] + (["AUTO"] if backend!="AUTO" else [])
    for b in order:
        flag = _backend_flag(b)
        cap = cv2.VideoCapture(index, flag) if flag is not None else cv2.VideoCapture(index)
        if not cap.isOpened():
            cap.release(); continue
        if size:
            w,h = size; cap.set(cv2.CAP_PROP_FRAME_WIDTH, w); cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
        for _ in range(max(0,warmup)): cap.read()
        ok, frame = cap.read(); cap.release()
        if ok and isinstance(frame, np.ndarray) and frame.size>0:
            return frame, {"backend_used": b, "shape": tuple(frame.shape)}
    return None, {"backend_used": None, "shape": None}

def bgr2rgb(img: np.ndarray) -> np.ndarray:
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# ç”»åƒèª­è¾¼ãƒ˜ãƒ«ãƒ‘ãƒ¼
def imread_color(path: str) -> Optional[np.ndarray]:
    if not path:
        return None
    img = cv2.imread(path, cv2.IMREAD_COLOR)
    return img if isinstance(img, np.ndarray) and img.size > 0 else None

# ============ å·®åˆ†å‡¦ç†ï¼ˆåŸºæº– vs ç¾åœ¨ï¼‰ ============

def compare_to_baseline(baseline_bgr: np.ndarray, current_bgr: np.ndarray, cfg: Dict[str,Any]) -> Dict[str,Any]:
    # ç”»è³ªæ•´åˆï¼ˆåŒå€ç‡ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«ãƒ»ã‚·ãƒ£ãƒ¼ãƒ—/æ˜ã‚‹ã•åˆã‚ã›ï¼‰
    a, b = quality_harmonize_pair(baseline_bgr, current_bgr,
                                  target_short=cfg.get("target_short", 720),
                                  match_sharp=True, match_hist=True, denoise='none')
    a, b = ensure_same_size(a, b)

    # ã‚ºãƒ¬åˆ¤å®šâ†’æ•´åˆ—ï¼ˆä»»æ„ï¼‰
    aligned_method = "NONE"
    if cfg.get("align_mode","AUTO") != "OFF":
        misaligned, _d = camera_misaligned(a, b, shift_px_thresh=cfg.get("shift_px_thresh", 6.0), homography_checks=True)
        if misaligned:
            if cfg.get("align_mode","AUTO") in ("AUTO","ECC"):
                b_ecc, _warp = align_ecc(a, b)
                if b_ecc is not None:
                    b = b_ecc; aligned_method = "ECC"
            if aligned_method == "NONE" and cfg.get("align_mode","AUTO") in ("AUTO","H"):
                b_h, _H = align_homography(a, b)
                if b_h is not None:
                    b = b_h; aligned_method = "H"

    # å³å¯†ä¸€è‡´ãªã‚‰absdiffèµ¤æ ã€ãã†ã§ãªã‘ã‚Œã°ç…§æ˜ã«å¼·ã„ãƒã‚¹ã‚¯
    vis_boxes, th_mask, boxes = None, None, []
    strict_same = (aligned_method=="NONE")
    if strict_same:
        vis_boxes, th_mask, boxes = difference_boxes(a, b, min_wh=cfg.get("min_wh", 15), bin_thresh=None)
    else:
        th_mask = fused_diff_mask(a, b)
        vis_boxes, boxes = boxes_from_mask(a, th_mask, min_wh=cfg.get("min_wh", 15))

    diff_ratio = float((th_mask>0).sum()) / float(th_mask.size)
    overlay = make_boxes_overlay_transparent(a, b, boxes, alpha=0.5, draw_border=True) if boxes else a.copy()
    clusters = cluster_dense_boxes(boxes, a.shape, dilate_iter=3, min_count=6, min_wh=30)
    clusters_vis = draw_clusters_only(a, clusters, color=(0,0,255), thickness=6, show_count=True)

    # SSIMï¼ˆãƒã‚¹ã‚¯ãªã—ç°¡æ˜“ï¼‰
    try:
        from skimage.metrics import structural_similarity as ssim
        ss = ssim(cv2.cvtColor(a, cv2.COLOR_BGR2GRAY), cv2.cvtColor(b, cv2.COLOR_BGR2GRAY))
    except Exception:
        ss = None

    # è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›£è¦–
    targets_cfg = cfg.get("targets", []) or []
    target_results = []
    for t in targets_cfg:
        try:
            curr_ratio = ratio_for_target(b, t)
            base_ratio = float(t.get("base_ratio", 0.0))
            direction = t.get("direction", "decrease")  # or "increase"
            thr = float(t.get("threshold_pct", 5.0)) / 100.0
            delta = curr_ratio - base_ratio
            if direction == "increase":
                alert = (delta >= thr)
            else:  # decrease
                alert = (-delta >= thr)
            target_results.append({
                "name": t.get("name", "target"),
                "curr_ratio": curr_ratio,
                "base_ratio": base_ratio,
                "delta": delta,
                "direction": direction,
                "threshold_pct": t.get("threshold_pct", 5.0),
                "alert": bool(alert)
            })
        except Exception as e:
            target_results.append({"name": t.get("name","target"), "error": str(e)})

    # Compose a color overlay for all targets (for live preview)
    target_overlay = a.copy()
    if targets_cfg:
        accum = np.zeros(a.shape[:2], np.uint8)
        color_map = [(0,255,255),(255,128,0),(0,200,0),(220,0,120),(120,0,220),(0,180,255)]
        for i, t in enumerate(targets_cfg):
            try:
                m = _target_mask_for_img(b, t, t.get("roi"))
                # keep a softer mask for visualization
                col = color_map[i % len(color_map)]
                mask3 = cv2.cvtColor(m, cv2.COLOR_GRAY2BGR)
                tint = np.full_like(target_overlay, col, dtype=np.uint8)
                target_overlay = np.where(mask3>0, cv2.addWeighted(target_overlay, 0.4, tint, 0.6, 0), target_overlay)
                accum = cv2.bitwise_or(accum, m)
            except Exception:
                continue

    return {
        "A": a, "B": b,
        "vis_boxes": vis_boxes, "mask": th_mask, "overlay": overlay, "clusters_vis": clusters_vis,
        "boxes": boxes, "diff_ratio": diff_ratio, "ssim": ss,
        "aligned": aligned_method,
        "target_results": target_results,
        "target_overlay": target_overlay
    }

# ============ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============
def run_test_case(pathA: str, pathB: str, cfg: Dict[str,Any], out_dir: Path) -> Dict[str,Any]:
    a = imread_color(pathA)
    b = imread_color(pathB)
    if a is None or b is None:
        return {"ok": False, "error": f"èª­è¾¼å¤±æ•— A={pathA}, B={pathB}"}
    res = compare_to_baseline(a, b, cfg)
    out_dir.mkdir(parents=True, exist_ok=True)
    # ä¿å­˜
    cv2.imwrite(str(out_dir/"A_baseline.png"), a)
    cv2.imwrite(str(out_dir/"B_compare.png"), b)
    cv2.imwrite(str(out_dir/"diff_boxes.png"), res["vis_boxes"])
    cv2.imwrite(str(out_dir/"diff_mask.png"), res["mask"])
    cv2.imwrite(str(out_dir/"diff_boxesx2.png"), res["clusters_vis"])
    # è¦ç´„
    return {
        "ok": True,
        "A": pathA,
        "B": pathB,
        "aligned": res["aligned"],
        "ssim": res["ssim"],
        "diff_ratio": res["diff_ratio"],
        "boxes": len(res["boxes"]),
        "dir": str(out_dir)
    }


# ============ UIï¼šã‚¹ãƒ†ãƒƒãƒ— 1ï¼ˆåŸºæº–ï¼‰ ============

def ui_step_baseline():
    st.header("â‘  åŸºæº–ã‚’æ’®å½± / èª­ã¿è¾¼ã¿")
    colL, colR = st.columns(2)

    with colL:
        st.markdown("#### ğŸ“¸ ã‚«ãƒ¡ãƒ©ã§æ’®å½±")
        idx = st.number_input("ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ç•ªå·", 0, 10, ss.get("cam_index",0), 1, key="k_cam_index")
        be  = st.selectbox("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", ["AUTO","AVFOUNDATION","QT","V4L2","DSHOW"],
                           index=(1 if sys.platform=="darwin" else 0), key="k_backend")
        if st.button("ğŸ“· åŸºæº–ã‚’æ’®ã‚‹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§1æšï¼‰", use_container_width=True, type="primary"):
            frame, diag = capture_frame(idx, be)
            if frame is None:
                st.error("ã‚«ãƒ¡ãƒ©å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒã‚¤ã‚¹ç•ªå·/ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            else:
                session = new_session_dir()
                base_path = str(Path(session)/"baseline.png")
                cv2.imwrite(base_path, frame)
                ss.session_dir = session
                ss.baseline_path = base_path
                ss.cam_index = idx
                ss.backend = be
                ss.cam_diag = diag
                ss.phase = "BASELINE_SET"
                st.success("åŸºæº–ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼æ¬¡ã¸é€²ã‚ã¾ã™ã€‚")
                st.rerun()

    with colR:
        st.markdown("#### ğŸ–¼ ç”»åƒã‹ã‚‰èª­ã¿è¾¼ã‚€")
        up = st.file_uploader("åŸºæº–ç”»åƒï¼ˆPNG/JPGï¼‰", type=["png","jpg","jpeg"])
        if up is not None:
            data = np.frombuffer(up.read(), np.uint8)
            img = cv2.imdecode(data, cv2.IMREAD_COLOR)
            if img is None:
                st.error("ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                session = new_session_dir()
                base_path = str(Path(session)/"baseline.png")
                cv2.imwrite(base_path, img)
                ss.session_dir = session
                ss.baseline_path = base_path
                ss.phase = "BASELINE_SET"
                st.success("åŸºæº–ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼æ¬¡ã¸é€²ã‚ã¾ã™ã€‚")
                st.rerun()

    # åŸºæº–ãŒã§ããŸã‚‰è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¿½åŠ UI
    if ss.get("baseline_path"):
        st.markdown("---")
        st.subheader("ğŸ¯ ç›£è¦–ã™ã‚‹è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¿½åŠ ï¼ˆä»»æ„ï¼‰")
        render_color_target_editor()

# ============ UIï¼šã‚¹ãƒ†ãƒƒãƒ— 2ï¼ˆè¨­å®šï¼‰ ============

def ui_step_config():
    st.header("â‘¡ è¨­å®š")
    with st.form("cfg_form", clear_on_submit=False):
        st.markdown("**æ’®å½±**")
        interval = st.slider("æ’®å½±é–“éš”ï¼ˆç§’ï¼‰â±ï¸", 10, 600, 60, 5)
        target_short = st.slider("å…±é€šãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«çŸ­è¾ºï¼ˆpxï¼‰", 360, 1440, 720, 60)

        st.markdown("---")
        st.markdown("**æ•´åˆ—ã¨æ¤œå‡º**")
        align_mode = st.selectbox("æ•´åˆ—ãƒ¢ãƒ¼ãƒ‰", ["AUTO","ECC","H","OFF"], help="AUTOæ¨å¥¨")
        shift_thresh = st.slider("ã‚ºãƒ¬åˆ¤å®šã—ãã„å€¤(px)", 1.0, 20.0, 6.0, 0.5)
        min_wh = st.slider("æœ€å°ãƒœãƒƒã‚¯ã‚¹å¹…/é«˜ã•(px)", 5, 100, 15, 1)

        st.markdown("---")
        submitted = st.form_submit_button("âœ… è¨­å®šã‚’ä¿å­˜ã—ã¦æ¬¡ã¸", use_container_width=True)
        if submitted:
            ss.config = {
                "interval": int(interval),
                "target_short": int(target_short),
                "align_mode": align_mode,
                "shift_px_thresh": float(shift_thresh),
                "min_wh": int(min_wh),
                "camera": {"index": ss.cam_index, "backend": ss.backend},
                "targets": ss.get("targets", [])
            }
            save_config(ss.session_dir, ss.config)
            ss.phase = "CONFIG_SET"
            # æ¬¡å›æ’®å½±æ™‚åˆ»ã¯ã‚¹ã‚¿ãƒ¼ãƒˆæ™‚ã«ã‚»ãƒƒãƒˆã™ã‚‹ï¼ˆåœæ­¢ä¸­ã«ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ã•ã›ãªã„ï¼‰
            ss.next_shot_ts = 0.0
            st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            st.rerun()

    st.markdown("---")
    with st.expander("ğŸ¯ ç›£è¦–ã™ã‚‹è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¨­å®šï¼ˆä»»æ„ï¼‰", expanded=True):
        render_color_target_editor()

# ============ UIï¼šã‚¹ãƒ†ãƒƒãƒ— 3ï¼ˆç›£è¦–ï¼‰ ============

def ui_step_run():
    st.header("â‘¢ ç›£è¦–ã‚¹ã‚¿ãƒ¼ãƒˆ")
    colA, colB = st.columns([2,1])

    with colB:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼†æ“ä½œ
        running = ss.get("phase") == "RUNNING"
        status_badge = f"<span class='big-badge {'ok-badge' if running else 'ng-badge'}'>{'ğŸŸ¢ ç›£è¦–ä¸­' if running else 'ğŸ”´ åœæ­¢ä¸­'}</span>"
        st.markdown(status_badge, unsafe_allow_html=True)
        st.write("")

        c1, c2 = st.columns(2)
        if c1.button("â–¶ï¸ ã‚¹ã‚¿ãƒ¼ãƒˆ", use_container_width=True):
            ss.phase = "RUNNING"
            # ã‚¹ã‚¿ãƒ¼ãƒˆæ™‚ã«æ¬¡å›æ’®å½±æ™‚åˆ»ã‚’ã‚»ãƒƒãƒˆ
            ss.next_shot_ts = time.time() + ss.config["interval"]
            st.rerun()
        if c2.button("â¸ åœæ­¢", use_container_width=True):
            ss.phase = "PAUSED"
            st.rerun()

        st.markdown("---")
        # ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³
        if running and ss.get("next_shot_ts", 0) > 0:
            target_ms = int(ss.next_shot_ts * 1000)
            interval_s = int(ss.config.get("interval", 60))
            st.components.v1.html(f"""
            <div style='margin:4px 0 10px 0;'>
              æ¬¡ã®æ’®å½±ã¾ã§: <b><span id='cd_secs'>--</span> ç§’</b> â³
              <div style='height:8px;background:#222;border-radius:6px;overflow:hidden;margin-top:6px;'>
                <div id='cd_bar' style='height:100%;width:0%;background:#3b82f6;'></div>
              </div>
            </div>
            <script>
            const target = {target_ms};
            const interval = {interval_s};
            function tick(){{
              const now = Date.now();
              const remain = Math.max(0, Math.ceil((target - now)/1000));
              document.getElementById('cd_secs').textContent = remain;
              const p = 100 * Math.min(1, Math.max(0, (interval - remain)/interval));
              document.getElementById('cd_bar').style.width = p + '%';
            }}
            tick();
            setInterval(tick, 250);
            </script>
            """, height=60)
        else:
            st.caption("åœæ­¢ä¸­ï¼ˆã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ãªã—ï¼‰")

        # ZIP DL
        if st.button("ğŸ’¾ ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", use_container_width=True):
            zpath = make_zip(ss.session_dir)
            with open(zpath, "rb") as f:
                st.download_button("ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name=Path(zpath).name, mime="application/zip", use_container_width=True)

        st.markdown("---")
        st.caption("åŸºæº–ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        base = cv2.imread(ss.baseline_path, cv2.IMREAD_COLOR)
        if base is not None:
            st.image(bgr2rgb(base), use_container_width=True)

    with colA:
        # ãƒ©ã‚¤ãƒ–å·®åˆ†
        st.subheader("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å·®åˆ†")
        ph_cols = st.columns(3)
        phA, phB, phD = ph_cols[0].empty(), ph_cols[1].empty(), ph_cols[2].empty()
        info = st.empty()

        # RUNNING ã®ã¨ãã ã‘ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆãƒãƒ©ã¤ãæŠ‘åˆ¶ï¼‰
        running = ss.get("phase") == "RUNNING"
        if running:
            st_autorefresh(interval=max(1000, int(ss.config.get("interval", 60) * 1000)), key="tick-live")

        # æ¡ä»¶ï¼šRUNNINGãªã‚‰æ™‚åˆ»åˆ°é”ã§æ’®å½±â†’å·®åˆ†â†’ä¿å­˜
        if ss.phase == "RUNNING" and time.time() >= ss.next_shot_ts:
            # æ’®å½±
            frame, diag = capture_frame(ss.config["camera"]["index"], ss.config["camera"]["backend"])
            if frame is not None:
                # å·®åˆ†
                baseline = cv2.imread(ss.baseline_path, cv2.IMREAD_COLOR)
                res = compare_to_baseline(baseline, frame, ss.config)
                # ä¿å­˜
                tsname = datetime.now().strftime("%Y-%m-%dT%H-%M-%S")
                cap_path = str(Path(ss.session_dir)/"captures"/f"{tsname}.jpg")
                diff_path = str(Path(ss.session_dir)/"diffs"/f"{tsname}_diff.png")
                diffx2_path = str(Path(ss.session_dir)/"diffs"/f"{tsname}_diffx2.png")
                mask_path = str(Path(ss.session_dir)/"diffs"/f"{tsname}_mask.png")
                cv2.imwrite(cap_path, frame)
                cv2.imwrite(diff_path, res["vis_boxes"])
                cv2.imwrite(diffx2_path, res["clusters_vis"])
                cv2.imwrite(mask_path, res["mask"])
                append_index(ss.session_dir, {
                    "ts": tsname, "capture": Path(cap_path).name,
                    "aligned": res["aligned"], "ssim": (res["ssim"] if res["ssim"] is not None else -1),
                    "diff_ratio": res["diff_ratio"], "boxes": len(res["boxes"])
                })
                # Save target overlay image if present
                if isinstance(res.get("target_overlay"), np.ndarray):
                    tov_path = str(Path(ss.session_dir)/"diffs"/f"{tsname}_targets.png")
                    cv2.imwrite(tov_path, res["target_overlay"])
                ss.last_metrics = {"ts": tsname, "aligned": res["aligned"], "ssim": res["ssim"], "diff_ratio": res["diff_ratio"], "boxes": len(res["boxes"])}
            # æ¬¡å›æ™‚åˆ»
            ss.next_shot_ts = time.time() + ss.config["interval"]

        # è¡¨ç¤ºï¼ˆç›´è¿‘ã®æ’®å½±çµæœ or æœ€æ–°ã®ä¿å­˜æ¸ˆã¿ï¼‰
        baseline = cv2.imread(ss.baseline_path, cv2.IMREAD_COLOR)
        try:
            latest_list = sorted(glob.glob(str(Path(ss.session_dir)/"captures/*.jpg")))
            latest_cap = latest_list[-1] if latest_list else None
        except Exception:
            latest_cap = None
        latest_diff = None
        latest_diffx2 = None
        latest_mask = None
        if latest_cap:
            tsname = Path(latest_cap).stem
            latest_diff = Path(ss.session_dir)/"diffs"/f"{tsname}_diff.png"
            latest_diffx2 = Path(ss.session_dir)/"diffs"/f"{tsname}_diffx2.png"
            latest_mask = Path(ss.session_dir)/"diffs"/f"{tsname}_mask.png"

        if latest_cap and baseline is not None:
            phA.image(bgr2rgb(baseline), caption="åŸºæº–", use_container_width=True)
            imgB = cv2.imread(latest_cap, cv2.IMREAD_COLOR)
            phB.image(bgr2rgb(imgB), caption="ä»Šå›ã‚·ãƒ§ãƒƒãƒˆ", use_container_width=True)
            if latest_diff and latest_mask and latest_diff.exists() and latest_mask.exists():
                grid = st.columns([2,2,1])
                with grid[0]:
                    phD.image(bgr2rgb(cv2.imread(str(latest_diff))), caption="å·®åˆ†ï¼ˆèµ¤æ ãƒ»å°ï¼‰", use_container_width=True)
                with grid[1]:
                    st.image(bgr2rgb(cv2.imread(str(latest_diffx2))), caption="å·®åˆ†ï¼ˆå¤§æ ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰", use_container_width=True)
                with grid[2]:
                    st.image(cv2.imread(str(latest_mask), cv2.IMREAD_GRAYSCALE), clamp=True, caption="å·®åˆ†ãƒã‚¹ã‚¯", use_container_width=True)
                # Target overlay toggle
                if ss.config.get("targets"):
                    show_tov = st.checkbox("ğŸ¯ è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’è¡¨ç¤º", value=False, key="k_show_tov")
                    if show_tov and 'res' in locals() and isinstance(res.get("target_overlay"), np.ndarray):
                        st.image(bgr2rgb(res["target_overlay"]), caption="è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆä»Šå›ï¼‰", use_container_width=True)

        lm = ss.get("last_metrics") or {}
        info.info(f"æ•´åˆ—: {lm.get('aligned','-')} / SSIM: {('-' if lm.get('ssim') in (None,-1) else f'{lm.get('ssim'):.4f}')} / å·®åˆ†ç‡: {lm.get('diff_ratio','-') if isinstance(lm.get('diff_ratio'),str) else f'{(lm.get('diff_ratio') or 0)*100:.2f}%'} / ãƒœãƒƒã‚¯ã‚¹æ•°: {lm.get('boxes','-')}")

        # è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ©ã‚¤ãƒ–çŠ¶æ…‹
        if ss.config.get("targets"):
            st.markdown("---")
            st.markdown("#### ğŸ¯ è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®çŠ¶æ…‹")
            latest_res_targets = res.get("target_results") if 'res' in locals() else None
            # ç›´è¿‘ã®çµæœãŒç„¡ã„å ´åˆã¯æœ€æ–°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‹ã‚‰å†è¨ˆç®—
            if latest_res_targets is None and latest_cap:
                tmp_imgB = cv2.imread(latest_cap, cv2.IMREAD_COLOR)
                tmp_cmp = compare_to_baseline(baseline, tmp_imgB, ss.config)
                latest_res_targets = tmp_cmp.get("target_results")
            if latest_res_targets:
                for tr in latest_res_targets:
                    if tr.get("error"):
                        st.warning(f"{tr['name']}: {tr['error']}")
                        continue
                    badge = "ğŸ›ï¸" if tr.get("alert") else "âœ…"
                    st.write(f"{badge} **{tr['name']}**  ç¾åœ¨: {tr['curr_ratio']*100:.2f}%  (åŸºæº– {tr['base_ratio']*100:.2f}% / Î” {tr['delta']*100:.2f}% / æ¡ä»¶ {tr['direction']} {tr['threshold_pct']}%)")
            else:
                st.caption("ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ’®å½±å¾…ã¡ã§ã™ã€‚")
            # Compact visualization for current masks
            if latest_res_targets and ss.config.get("targets"):
                st.caption("ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚¹ã‚¯ã®æ¦‚è¦³")
                # recompute masks for the latest capture for preview
                imgB_now = cv2.imread(latest_cap, cv2.IMREAD_COLOR) if latest_cap else None
                if imgB_now is not None:
                    try:
                        tmp_cmp = compare_to_baseline(baseline, imgB_now, ss.config)
                        st.image(bgr2rgb(tmp_cmp["target_overlay"]), caption="è‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆæœ€æ–°ï¼‰", use_container_width=True)
                    except Exception:
                        pass

    # å±¥æ­´ã‚®ãƒ£ãƒ©ãƒªãƒ¼
    st.markdown("---")
    st.subheader("ğŸ“š å±¥æ­´ã‚®ãƒ£ãƒ©ãƒªãƒ¼")
    caps = sorted(glob.glob(str(Path(ss.session_dir)/"captures/*.jpg")))
    ncols = st.slider("åˆ—æ•°", 2, 6, 4, 1, key="k_cols")
    cols = st.columns(ncols)
    for i, cp in enumerate(caps):
        with cols[i % ncols]:
            ts = Path(cp).stem
            dp = Path(ss.session_dir)/"diffs"/f"{ts}_diff.png"
            st.image(bgr2rgb(cv2.imread(cp)), caption=ts, use_container_width=True)
            if dp.exists():
                with st.expander("å·®åˆ†ã‚’è¡¨ç¤º"):
                    st.image(bgr2rgb(cv2.imread(str(dp))), caption="å·®åˆ†ï¼ˆèµ¤æ ãƒ»å°ï¼‰", use_container_width=True)
                    dpx2 = Path(ss.session_dir)/"diffs"/f"{ts}_diffx2.png"
                    if dpx2.exists():
                        st.image(bgr2rgb(cv2.imread(str(dpx2))), caption="å·®åˆ†ï¼ˆå¤§æ ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰", use_container_width=True)

# ============ UI: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ ============ 
def ui_mode_test():
    st.header("ğŸ“¦ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒãƒƒãƒã§ç”»åƒãƒšã‚¢ã‚’æ¯”è¼ƒï¼‰")

    # 1) å…¥åŠ›ç”»åƒã®å ´æ‰€
    colA, colB = st.columns([2,1])
    with colA:
        st.markdown("**ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**")
        default_dir = "test_images"
        test_dir = st.text_input("æ¤œç´¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value=default_dir, help="PNG/JPG ã‚’æ¢ç´¢ã—ã¾ã™")
        paths = []
        if test_dir and Path(test_dir).exists():
            paths = sorted([p for p in glob.glob(str(Path(test_dir)/"*.png"))] + [p for p in glob.glob(str(Path(test_dir)/"*.jpg"))] + [p for p in glob.glob(str(Path(test_dir)/"*.jpeg"))])
        if not paths:
            st.warning("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.caption(f"{len(paths)} æšè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

    with colB:
        st.markdown("**ã‚¯ã‚¤ãƒƒã‚¯è¿½åŠ ï¼ˆã‚ˆãä½¿ã†çµ„ã¿åˆã‚ã›ï¼‰**")
        # æ—¢çŸ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšã‚¢ãŒã‚ã‚‹å ´åˆã¯ææ¡ˆ
        candidates = []
        def has(name): return any(Path(p).name == name for p in paths)
        if has("closedoor.png") and has("opendoor.png"):
            candidates.append(("closedoor.png","opendoor.png"))
        if has("closedoor.png") and has("closedoor_different_colors.png"):
            candidates.append(("closedoor.png","closedoor_different_colors.png"))
        if has("easy.png") and has("easy_wrong.png"):
            candidates.append(("easy.png","easy_wrong.png"))
        if has("IMG_4726.PNG") and has("IMG_4728.PNG"):
            candidates.append(("IMG_4726.PNG","IMG_4728.PNG"))

        if candidates:
            for a,b in candidates:
                if st.button(f"ï¼‹ è¿½åŠ : {a} vs {b}", use_container_width=True):
                    pa = str(Path(test_dir)/a); pb = str(Path(test_dir)/b)
                    if (pa,pb) not in ss.test_pairs:
                        ss.test_pairs.append((pa,pb))
                        st.toast(f"è¿½åŠ : {a} vs {b}")
                        st.rerun()
        else:
            st.caption("æ—¢çŸ¥ã®çµ„ã¿åˆã‚ã›å€™è£œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # 2) æ‰‹å‹•ã§ãƒšã‚¢è¿½åŠ 
    st.markdown("---")
    st.markdown("**æ‰‹å‹•ã§ãƒšã‚¢ã‚’è¿½åŠ **")
    c1, c2, c3 = st.columns([5,5,2])
    with c1:
        selA = st.selectbox("Aï¼ˆåŸºæº–ï¼‰", options=["(é¸æŠ)"]+paths, index=0, key="selA")
    with c2:
        selB = st.selectbox("Bï¼ˆæ¯”è¼ƒï¼‰", options=["(é¸æŠ)"]+paths, index=0, key="selB")
    with c3:
        if st.button("è¿½åŠ ", use_container_width=True, disabled=not(selA!='(é¸æŠ)' and selB!='(é¸æŠ)')):
            pair = (selA, selB)
            if pair not in ss.test_pairs:
                ss.test_pairs.append(pair)
                st.toast("ãƒšã‚¢ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                st.rerun()

    # 3) ç¾åœ¨ã®ãƒšã‚¢ä¸€è¦§
    st.markdown("---")
    st.subheader("ğŸ“„ å®Ÿè¡Œã‚­ãƒ¥ãƒ¼")
    if not ss.test_pairs:
        st.info("ãƒšã‚¢ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    else:
        # è¡¨ç¤º & å‰Šé™¤ãƒœã‚¿ãƒ³
        rm_idxs = []
        for i, (pa, pb) in enumerate(ss.test_pairs):
            cols = st.columns([5,5,1,1])
            cols[0].markdown(f"**A**: `{pa}`")
            cols[1].markdown(f"**B**: `{pb}`")
            if cols[2].button("ğŸ‘€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key=f"pv{i}"):
                colp = st.columns(2)
                with colp[0]:
                    st.image(bgr2rgb(cv2.imread(pa)), caption="A", use_container_width=True)
                with colp[1]:
                    st.image(bgr2rgb(cv2.imread(pb)), caption="B", use_container_width=True)
            if cols[3].button("ğŸ—‘ï¸", key=f"rm{i}"):
                rm_idxs.append(i)
        for idx in reversed(rm_idxs):
            ss.test_pairs.pop(idx)

    # 4) è¨­å®šï¼ˆæ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
    st.markdown("---")
    st.subheader("âš™ï¸ è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰")
    cfg = {
        "interval": 0,
        "target_short": st.slider("å…±é€šãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«çŸ­è¾ºï¼ˆpxï¼‰", 360, 1440, 720, 60, key="t_target"),
        "align_mode": st.selectbox("æ•´åˆ—ãƒ¢ãƒ¼ãƒ‰", ["AUTO","ECC","H","OFF"], index=0, key="t_align"),
        "shift_px_thresh": st.slider("ã‚ºãƒ¬åˆ¤å®šã—ãã„å€¤(px)", 1.0, 20.0, 6.0, 0.5, key="t_shift"),
        "min_wh": st.slider("æœ€å°ãƒœãƒƒã‚¯ã‚¹å¹…/é«˜ã•(px)", 5, 100, 15, 1, key="t_minwh"),
    }

    # 5) å®Ÿè¡Œ
    st.markdown("---")
    run_col1, run_col2 = st.columns([1,4])
    out_root = Path("artifacts_gui") / datetime.now().strftime("%Y-%m-%d_%H%M%S")
    if run_col1.button("â–¶ï¸ é¸æŠãƒšã‚¢ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True, disabled=not ss.test_pairs):
        results = []
        for (pa, pb) in ss.test_pairs:
            case_dir = out_root / (Path(pa).stem + "_vs_" + Path(pb).stem)
            r = run_test_case(pa, pb, cfg, case_dir)
            results.append(r)
        st.session_state["test_results"] = results
        st.session_state["test_out_root"] = str(out_root)
        st.success("ãƒ†ã‚¹ãƒˆå®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸã€‚ä¸‹ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    # 6) çµæœè¡¨ç¤º
    res = st.session_state.get("test_results")
    if res:
        st.subheader("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ")
        for r in res:
            st.markdown("---")
            if not r.get("ok"):
                st.error(r.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"))
                continue
            st.markdown(f"**A â†’ B**  \n`{r['A']}`  \n`{r['B']}`")
            cols = st.columns([2,2,2,2,2])
            case_dir = Path(r["dir"])
            with cols[0]:
                st.image(bgr2rgb(cv2.imread(str(case_dir/"A_baseline.png"))), caption="Aï¼ˆåŸºæº–ï¼‰", use_container_width=True)
            with cols[1]:
                st.image(bgr2rgb(cv2.imread(str(case_dir/"B_compare.png"))), caption="Bï¼ˆæ¯”è¼ƒï¼‰", use_container_width=True)
            with cols[2]:
                st.image(bgr2rgb(cv2.imread(str(case_dir/"diff_boxes.png"))), caption="å·®åˆ†ï¼ˆèµ¤æ ãƒ»å°ï¼‰", use_container_width=True)
            with cols[3]:
                st.image(bgr2rgb(cv2.imread(str(case_dir/"diff_boxesx2.png"))), caption="å·®åˆ†ï¼ˆå¤§æ ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰", use_container_width=True)
            with cols[4]:
                st.image(cv2.imread(str(case_dir/"diff_mask.png"), cv2.IMREAD_GRAYSCALE), clamp=True, caption="å·®åˆ†ãƒã‚¹ã‚¯", use_container_width=True)
            ssim_txt = "-" if r["ssim"] in (None, -1) else f"{r['ssim']:.4f}"
            st.caption(f"æ•´åˆ—: {r['aligned']} / SSIM: {ssim_txt} / å·®åˆ†ç‡: {r['diff_ratio']*100:.2f}% / ãƒœãƒƒã‚¯ã‚¹æ•°: {r['boxes']}")
        # ZIP
        with st.expander("ğŸ“¦ æˆæœç‰©"):
            st.code(st.session_state.get("test_out_root",""))

# ============ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºé·ç§»ï¼‰ ============
def main():
    st.caption(f"Auto-refresh: {_AUTOREFRESH_IMPL}  â€¢  ã‚»ãƒƒã‚·ãƒ§ãƒ³: `{ss.session_dir or 'æœªä½œæˆ'}`")
    if ss.mode == "ãƒ†ã‚¹ãƒˆ":
        ui_mode_test()
        return
    # ä»¥é™ã¯ç›£è¦–ãƒ¢ãƒ¼ãƒ‰
    phase = ss.get("phase","INIT")
    if phase == "INIT":
        ui_step_baseline()
    elif phase == "BASELINE_SET":
        st.success("åŸºæº–ç”»åƒ OKï¼ã¤ãã¯è¨­å®šã§ã™ã€‚")
        ui_step_config()
    elif phase == "CONFIG_SET":
        st.info("è¨­å®šãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚ã‚¹ã‚¿ãƒ¼ãƒˆã§ãã¾ã™ï¼")
        ui_step_run()
    elif phase in ("RUNNING", "PAUSED"):
        ui_step_run()
    else:
        st.warning("æœªçŸ¥ã®çŠ¶æ…‹ã§ã™ã€‚åˆæœŸåŒ–ã—ã¾ã™ã€‚")
        _init_state()
        ui_step_baseline()

if __name__ == "__main__":
    main()